{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_w(W):\n",
    "    w1, w2 = W\n",
    "    dw1 = 0.2*w1\n",
    "    dw2 = 4*w2\n",
    "    return np.array([dw1, dw2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: w1 = -4.6, w2 = 1.2000000000000002\n",
      "Epoch 2: w1 = -4.231999999999999, w2 = -0.7200000000000002\n",
      "Epoch 3: w1 = -3.893439999999999, w2 = 0.43200000000000016\n",
      "Epoch 4: w1 = -3.5819647999999993, w2 = -0.2592000000000001\n",
      "Epoch 5: w1 = -3.2954076159999994, w2 = 0.1555200000000001\n",
      "Epoch 6: w1 = -3.0317750067199993, w2 = -0.09331200000000006\n",
      "Epoch 7: w1 = -2.7892330061823993, w2 = 0.05598720000000004\n",
      "Epoch 8: w1 = -2.5660943656878072, w2 = -0.03359232000000004\n",
      "Epoch 9: w1 = -2.360806816432783, w2 = 0.020155392000000022\n",
      "Epoch 10: w1 = -2.1719422711181604, w2 = -0.012093235200000017\n",
      "Epoch 11: w1 = -1.9981868894287076, w2 = 0.007255941120000012\n",
      "Epoch 12: w1 = -1.838331938274411, w2 = -0.0043535646720000085\n",
      "Epoch 13: w1 = -1.691265383212458, w2 = 0.0026121388032000056\n",
      "Epoch 14: w1 = -1.5559641525554613, w2 = -0.0015672832819200039\n",
      "Epoch 15: w1 = -1.4314870203510244, w2 = 0.0009403699691520025\n",
      "Epoch 16: w1 = -1.3169680587229424, w2 = -0.0005642219814912016\n",
      "Epoch 17: w1 = -1.211610614025107, w2 = 0.00033853318889472107\n",
      "Epoch 18: w1 = -1.1146817649030984, w2 = -0.00020311991333683268\n",
      "Epoch 19: w1 = -1.0255072237108505, w2 = 0.00012187194800209963\n",
      "Epoch 20: w1 = -0.9434666458139824, w2 = -7.312316880125978e-05\n",
      "Epoch 21: w1 = -0.8679893141488638, w2 = 4.387390128075587e-05\n",
      "Epoch 22: w1 = -0.7985501690169547, w2 = -2.6324340768453522e-05\n",
      "Epoch 23: w1 = -0.7346661554955983, w2 = 1.5794604461072116e-05\n",
      "Epoch 24: w1 = -0.6758928630559504, w2 = -9.476762676643271e-06\n",
      "Epoch 25: w1 = -0.6218214340114744, w2 = 5.686057605985963e-06\n",
      "Epoch 26: w1 = -0.5720757192905565, w2 = -3.4116345635915786e-06\n",
      "Epoch 27: w1 = -0.526309661747312, w2 = 2.046980738154947e-06\n",
      "Epoch 28: w1 = -0.484204888807527, w2 = -1.2281884428929686e-06\n",
      "Epoch 29: w1 = -0.44546849770292485, w2 = 7.36913065735781e-07\n",
      "Epoch 30: w1 = -0.40983101788669085, w2 = -4.4214783944146867e-07\n"
     ]
    }
   ],
   "source": [
    "def sgd(W, dw, lr):\n",
    "    W = W - lr * dw\n",
    "    return W\n",
    "\n",
    "\n",
    "def train_p1(optimizer, lr, epochs):\n",
    "    W = np.array([-5, -2], dtype=np.float32)\n",
    "    results = [W.tolist()]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Compute gradient\n",
    "        dw = df_w(W)\n",
    "        \n",
    "        # Update W using the provided optimization function\n",
    "        W = optimizer(W, dw, lr)\n",
    "\n",
    "        results.append(W.tolist())\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}: w1 = {W[0]}, w2 = {W[1]}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "results = train_p1(sgd, lr=0.4, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: w1 = -4.7, w2 = 0.3999999999999999\n",
      "Epoch 2: w1 = -4.268, w2 = 1.12\n",
      "Epoch 3: w1 = -3.7959199999999997, w2 = 0.13600000000000012\n",
      "Epoch 4: w1 = -3.3321248, w2 = -0.5192\n",
      "Epoch 5: w1 = -2.900299712, w2 = -0.22376000000000013\n",
      "Epoch 6: w1 = -2.5103691852799996, w2 = 0.19247199999999992\n",
      "Epoch 7: w1 = -2.1647817708031996, w2 = 0.16962160000000004\n",
      "Epoch 8: w1 = -1.8621011573166075, w2 = -0.04534951999999995\n",
      "Epoch 9: w1 = -1.599034781134315, w2 = -0.09841565599999999\n",
      "Epoch 10: w1 = -1.3715595061751098, w2 = -0.0068499368000000255\n",
      "Epoch 11: w1 = -1.1755282983250006, w2 = 0.04715284695999999\n",
      "Epoch 12: w1 = -1.006980996500446, w2 = 0.01757082248800001\n",
      "Epoch 13: w1 = -0.8622884857981419, w2 = -0.018305176733599993\n",
      "Epoch 14: w1 = -0.7382049212991013, w2 = -0.01427696426408\n",
      "Epoch 15: w1 = -0.6318708437716349, w2 = 0.004869499087575998\n",
      "Epoch 16: w1 = -0.5407915543816036, w2 = 0.0085993318583128\n",
      "Epoch 17: w1 = -0.4628044164236918, w2 = 0.00014505001370584102\n",
      "Epoch 18: w1 = -0.39604258245931434, w2 = -0.004256150925044647\n",
      "Epoch 19: w1 = -0.3388991105295668, w2 = -0.0013493702843663147\n",
      "Epoch 20: w1 = -0.289993427932919, w2 = 0.0017232643772124292\n",
      "Epoch 21: w1 = -0.24814098095861994, w2 = 0.0011916644553468863\n",
      "Epoch 22: w1 = -0.21232629861395325, w2 = -0.0005041328520021488\n",
      "Epoch 23: w1 = -0.1816793795247827, w2 = -0.0007470720832740878\n",
      "Epoch 24: w1 = -0.15545515720871045, w2 = 2.7944801018848055e-05\n",
      "Epoch 25: w1 = -0.1330157366181517, w2 = 0.00038191948194269836\n",
      "Epoch 26: w1 = -0.11381508212578322, w2 = 0.00010060344407338548\n",
      "Epoch 27: w1 = -0.09738584995205199, w2 = -0.00016077870774933352\n",
      "Epoch 28: w1 = -0.08332808286806326, w2 = -9.853533436149282e-05\n",
      "Epoch 29: w1 = -0.0712995143539851, w2 = 5.08287535662189e-05\n",
      "Epoch 30: w1 = -0.061007259235706914, w2 = 6.451629325061208e-05\n"
     ]
    }
   ],
   "source": [
    "def sgd_momentum(W, V, dw, lr, beta):\n",
    "    V = beta * V + (1 - beta) * dw\n",
    "    W = W - lr * V\n",
    "    return W, V\n",
    "\n",
    "\n",
    "def train_p2(optimizer, lr, beta, epochs):\n",
    "    W = np.array([-5, -2], dtype=np.float32)\n",
    "    V = np.array([0, 0], dtype=np.float32)\n",
    "    results = [W.tolist()]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Compute gradient\n",
    "        dw = df_w(W)\n",
    "        \n",
    "        # Update W using the provided optimization function\n",
    "        W, V = optimizer(W, V, dw, lr, beta)\n",
    "\n",
    "        results.append(W.tolist())\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}: w1 = {W[0]}, w2 = {W[1]}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "results = train_p2(sgd_momentum, lr=0.6, beta=0.5, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: w1 = -4.051321445330401, w2 = -1.05131677606536\n",
      "Epoch 2: w1 = -3.435197540710313, w2 = -0.59152342591607\n",
      "Epoch 3: w1 = -2.9589369293489796, w2 = -0.32943940499816177\n",
      "Epoch 4: w1 = -2.5654628900149308, w2 = -0.17756481857235581\n",
      "Epoch 5: w1 = -2.22920552377513, w2 = -0.09163256127358085\n",
      "Epoch 6: w1 = -1.9362675156207105, w2 = -0.04494498658095136\n",
      "Epoch 7: w1 = -1.6781768574274967, w2 = -0.020814229601575286\n",
      "Epoch 8: w1 = -1.4493498477990567, w2 = -0.009035585595074872\n",
      "Epoch 9: w1 = -1.245881993508816, w2 = -0.0036459054729884493\n",
      "Epoch 10: w1 = -1.0649030085077544, w2 = -0.001353509894550125\n",
      "Epoch 11: w1 = -0.9042022597717996, w2 = -0.00045644443087383853\n",
      "Epoch 12: w1 = -0.7619964948529877, w2 = -0.00013756292811056234\n",
      "Epoch 13: w1 = -0.6367784991349714, w2 = -3.626010194868877e-05\n",
      "Epoch 14: w1 = -0.5272152373016313, w2 = -8.113374556116915e-06\n",
      "Epoch 15: w1 = -0.43207850492177147, w2 = -1.4747341183766382e-06\n",
      "Epoch 16: w1 = -0.3501985066951054, w2 = -2.0278399084030003e-07\n",
      "Epoch 17: w1 = -0.28043464894887404, w2 = -1.8423118691859592e-08\n",
      "Epoch 18: w1 = -0.2216598344806836, w2 = -7.677427476337743e-10\n",
      "Epoch 19: w1 = -0.17275551249499957, w2 = 7.804519979765288e-12\n",
      "Epoch 20: w1 = -0.13261513350543708, w2 = -5.057948000729009e-13\n",
      "Epoch 21: w1 = -0.10015377919264787, w2 = 6.191235006401555e-14\n",
      "Epoch 22: w1 = -0.0743217708151839, w2 = -1.1337378100970054e-14\n",
      "Epoch 23: w1 = -0.05412012784634228, w2 = 2.8016670225324874e-15\n",
      "Epoch 24: w1 = -0.0386159157415847, w2 = -8.813411907873787e-16\n",
      "Epoch 25: w1 = -0.026955806616043014, w2 = 3.399211167787301e-16\n",
      "Epoch 26: w1 = -0.018376563327480278, w2 = -1.5658173063270338e-16\n",
      "Epoch 27: w1 = -0.012211609286904183, w2 = 8.449949845599187e-17\n",
      "Epoch 28: w1 = -0.007893317940141474, w2 = -5.263765950722017e-17\n",
      "Epoch 29: w1 = -0.004951102607005795, w2 = 3.7410799523619476e-17\n",
      "Epoch 30: w1 = -0.0030057708084714144, w2 = -3.005060842611838e-17\n"
     ]
    }
   ],
   "source": [
    "def rmsprop(W, S, dw, gamma, ep, lr):\n",
    "    S = gamma * S + (1 - gamma) * dw**2\n",
    "    W = W - lr * (dw / np.sqrt(S + ep))\n",
    "    return W, S\n",
    "\n",
    "def train_p3(optimizer, gamma, ep, lr, epochs):\n",
    "    W = np.array([-5, -2], dtype=np.float32)\n",
    "    S = np.array([0, 0], dtype=np.float32)\n",
    "    results = [W.tolist()]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Compute gradient\n",
    "        dw = df_w(W)\n",
    "        \n",
    "        # Update W using the provided optimization function\n",
    "        W, S = optimizer(W, S, dw, gamma, ep, lr)\n",
    "\n",
    "        results.append(W.tolist())\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}: w1 = {W[0]}, w2 = {W[1]}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "results = train_p3(rmsprop, gamma=0.9, ep=1e-6, lr=0.3 ,epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: w1 = -4.8000002, w2 = -1.8000002\n",
      "Epoch 2: w1 = -4.600254775652752, w2 = -1.6008248541864185\n",
      "Epoch 3: w1 = -4.400948465362033, w2 = -1.4031731381331956\n",
      "Epoch 4: w1 = -4.202277614312448, w2 = -1.2078789048955492\n",
      "Epoch 5: w1 = -4.004450290938027, w2 = -1.0159282878015319\n",
      "Epoch 6: w1 = -3.8076863242991874, w2 = -0.8284740581959538\n",
      "Epoch 7: w1 = -3.61221724703128, w2 = -0.6468427212355607\n",
      "Epoch 8: w1 = -3.41828612684455, w2 = -0.47252891000982167\n",
      "Epoch 9: w1 = -3.2261472680014704, w2 = -0.307170711028778\n",
      "Epoch 10: w1 = -3.0360657628979464, w2 = -0.15250000808216777\n",
      "Epoch 11: w1 = -2.848316872982822, w2 = -0.010264778912287581\n",
      "Epoch 12: w1 = -2.663185217944753, w2 = 0.11787395890527219\n",
      "Epoch 13: w1 = -2.4809637525779293, w2 = 0.23046003291351314\n",
      "Epoch 14: w1 = -2.301952512221825, w2 = 0.32635712988700927\n",
      "Epoch 15: w1 = -2.1264571103667507, w2 = 0.4048404051336537\n",
      "Epoch 16: w1 = -1.9547869761167105, w2 = 0.46564811939562323\n",
      "Epoch 17: w1 = -1.787253324847357, w2 = 0.5089865667782412\n",
      "Epoch 18: w1 = -1.6241668626574997, w2 = 0.5354930653913177\n",
      "Epoch 19: w1 = -1.4658352340485643, w2 = 0.5461701620536223\n",
      "Epoch 20: w1 = -1.3125602325028796, w2 = 0.5423069321388775\n",
      "Epoch 21: w1 = -1.1646348049361286, w2 = 0.5254009459598631\n",
      "Epoch 22: w1 = -1.0223398928716967, w2 = 0.49708956321288544\n",
      "Epoch 23: w1 = -0.8859411649661153, w2 = 0.4590941410862655\n",
      "Epoch 24: w1 = -0.7556857064184948, w2 = 0.41317691209209384\n",
      "Epoch 25: w1 = -0.6317987399629209, w2 = 0.36110806496261943\n",
      "Epoch 26: w1 = -0.514480459715166, w2 = 0.30463969490220383\n",
      "Epoch 27: w1 = -0.40390306236333906, w2 = 0.24548334637832941\n",
      "Epoch 28: w1 = -0.3002080594871815, w2 = 0.1852884771035601\n",
      "Epoch 29: w1 = -0.20350394987038872, w2 = 0.12562007037551898\n",
      "Epoch 30: w1 = -0.11386432157957514, w2 = 0.06793465026860437\n"
     ]
    }
   ],
   "source": [
    "def adam(W, V, S, t, dw, beta, ep, lr):\n",
    "    beta1, beta2 = beta\n",
    "    V = beta1 * V + (1 - beta1) * dw\n",
    "    S = beta2 * S + (1 - beta2) * dw**2\n",
    "    \n",
    "    V_corr = V / (1 - beta1**t)\n",
    "    S_corr = S / (1 - beta2**t)\n",
    "\n",
    "    W = W - lr * (V_corr / np.sqrt(S_corr) + ep)\n",
    "    return W, V, S\n",
    "\n",
    "\n",
    "def train_p4(optimizer, beta, ep, lr, epochs):\n",
    "    W = np.array([-5, -2], dtype=np.float32)\n",
    "    V = np.array([0, 0], dtype=np.float32)\n",
    "    S = np.array([0, 0], dtype=np.float32)\n",
    "    results = [W.tolist()]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Compute gradient\n",
    "        dw = df_w(W)\n",
    "        \n",
    "        # Update W using the provided optimization function\n",
    "        t = epoch + 1\n",
    "        W, V, S = optimizer(W, V, S, t, dw, beta, ep, lr)\n",
    "\n",
    "        results.append(W.tolist())\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}: w1 = {W[0]}, w2 = {W[1]}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "results = train_p4(adam, beta=[0.9, 0.999], ep=1e-6, lr=0.2, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
